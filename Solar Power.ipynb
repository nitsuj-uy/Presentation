{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx = pd.ExcelFile('Solar Energy.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_dat = pd.read_excel(xlsx, 'Actuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_hr_dat = pd.read_excel(xlsx, '4 Hour Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_dat = pd.read_excel(xlsx, 'Day Ahead Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                  datetime64[ns]\n",
      "Reading                       object\n",
      "Location Site Name            object\n",
      "Latitude                     float64\n",
      "Longitude                    float64\n",
      "PV                            object\n",
      "Capacity                      object\n",
      "Power(MW)                    float64\n",
      "dtype: object\n",
      "(832200, 8)\n"
     ]
    }
   ],
   "source": [
    "print(solar_dat.dtypes)\n",
    "print(solar_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading                       object\n",
      "Latitude                     float64\n",
      "Longitude                    float64\n",
      "PV                            object\n",
      "Capacity                      object\n",
      "Reading Date          datetime64[ns]\n",
      "Location Site Name            object\n",
      "Power(MW)                    float64\n",
      "dtype: object\n",
      "(87600, 8)\n"
     ]
    }
   ],
   "source": [
    "print(four_hr_dat.dtypes)\n",
    "print(four_hr_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading                       object\n",
      "Latitude                     float64\n",
      "Longitude                    float64\n",
      "PV                            object\n",
      "Capacity                      object\n",
      "Reading Date          datetime64[ns]\n",
      "Location Site Name            object\n",
      "Power(MW)                    float64\n",
      "dtype: object\n",
      "(87600, 8)\n"
     ]
    }
   ],
   "source": [
    "print(one_day_dat.dtypes)\n",
    "print(one_day_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_hr_dat = four_hr_dat[['Location Site Name', 'Reading Date', \"Power(MW)\"]]\n",
    "one_day_dat = one_day_dat[['Location Site Name', 'Reading Date', \"Power(MW)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_hr_dat = four_hr_dat.rename(columns = {\"Power(MW)\" : \"Power_4_Hour_Forecast\"})\n",
    "one_day_dat = one_day_dat.rename(columns = {\"Power(MW)\" : \"Day_Ahead_Forecast\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Location Site Name        Reading Date  Power_4_Hour_Forecast\n",
      "0       Bethel Array 2020-05-04 08:00:00                   29.0\n",
      "1       Bethel Array 2020-05-04 09:00:00                   36.1\n",
      "2       Bethel Array 2020-05-04 10:00:00                   31.3\n",
      "3       Bethel Array 2020-05-04 11:00:00                   35.8\n",
      "4       Bethel Array 2020-05-04 12:00:00                   35.3\n",
      "   Location Site Name        Reading Date  Day_Ahead_Forecast\n",
      "0  Preston Road Array 2020-01-01 00:00:00                 0.0\n",
      "1  Preston Road Array 2020-01-01 01:00:00                 0.0\n",
      "2  Preston Road Array 2020-01-01 02:00:00                 0.0\n",
      "3  Preston Road Array 2020-01-01 03:00:00                 0.0\n",
      "4  Preston Road Array 2020-01-01 04:00:00                 0.0\n"
     ]
    }
   ],
   "source": [
    "print(four_hr_dat.head(5))\n",
    "print(one_day_dat.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Preston Road Array', 'East Fork Array', \"Aaron's Creek Array\",\n",
       "       'Millvale Array', 'Lincoln Heights Array', 'Anstelt Array',\n",
       "       'Bethel Array', 'Owensville Array', 'Norwood Array',\n",
       "       'Oak Hills Array'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_day_dat[\"Location Site Name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bethel Array', \"Aaron's Creek Array\", 'Preston Road Array',\n",
       "       'East Fork Array', 'Owensville Array', 'Anstelt Array',\n",
       "       'Millvale Array', 'Oak Hills Array', 'Lincoln Heights Array',\n",
       "       'Norwood Array'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_hr_dat[\"Location Site Name\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__I have three datasets with data of actual, 4 hour forecats, and day ahead values. I want to compare these values against each other, however the dataset with the actuals contain location sites no included in the forecast datasets. So I have joined matching data together.__ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_hr_dat = four_hr_dat.rename(columns = {\"Reading Date\" : \"Date\"})\n",
    "one_day_dat = one_day_dat.rename(columns = {\"Reading Date\" : \"Date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_four_dat = four_hr_dat.merge(one_day_dat, how = 'inner', on = ['Date', 'Location Site Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one_four_dat = one_four_dat.rename(columns = {\"Reading Date\" : \"Date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location Site Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Power_4_Hour_Forecast</th>\n",
       "      <th>Day_Ahead_Forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 08:00:00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 09:00:00</td>\n",
       "      <td>36.1</td>\n",
       "      <td>14.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 10:00:00</td>\n",
       "      <td>31.3</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 11:00:00</td>\n",
       "      <td>35.8</td>\n",
       "      <td>31.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 12:00:00</td>\n",
       "      <td>35.3</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 13:00:00</td>\n",
       "      <td>32.5</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 14:00:00</td>\n",
       "      <td>18.1</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 15:00:00</td>\n",
       "      <td>10.6</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 16:00:00</td>\n",
       "      <td>9.4</td>\n",
       "      <td>21.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 17:00:00</td>\n",
       "      <td>6.3</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 18:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 19:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 21:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 22:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-04 23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-05 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-05 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-05 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bethel Array</td>\n",
       "      <td>2020-05-05 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Location Site Name                Date  Power_4_Hour_Forecast   \n",
       "0        Bethel Array 2020-05-04 08:00:00                   29.0  \\\n",
       "1        Bethel Array 2020-05-04 09:00:00                   36.1   \n",
       "2        Bethel Array 2020-05-04 10:00:00                   31.3   \n",
       "3        Bethel Array 2020-05-04 11:00:00                   35.8   \n",
       "4        Bethel Array 2020-05-04 12:00:00                   35.3   \n",
       "5        Bethel Array 2020-05-04 13:00:00                   32.5   \n",
       "6        Bethel Array 2020-05-04 14:00:00                   18.1   \n",
       "7        Bethel Array 2020-05-04 15:00:00                   10.6   \n",
       "8        Bethel Array 2020-05-04 16:00:00                    9.4   \n",
       "9        Bethel Array 2020-05-04 17:00:00                    6.3   \n",
       "10       Bethel Array 2020-05-04 18:00:00                    0.0   \n",
       "11       Bethel Array 2020-05-04 19:00:00                    0.0   \n",
       "12       Bethel Array 2020-05-04 20:00:00                    0.0   \n",
       "13       Bethel Array 2020-05-04 21:00:00                    0.0   \n",
       "14       Bethel Array 2020-05-04 22:00:00                    0.0   \n",
       "15       Bethel Array 2020-05-04 23:00:00                    0.0   \n",
       "16       Bethel Array 2020-05-05 00:00:00                    0.0   \n",
       "17       Bethel Array 2020-05-05 01:00:00                    0.0   \n",
       "18       Bethel Array 2020-05-05 02:00:00                    0.0   \n",
       "19       Bethel Array 2020-05-05 03:00:00                    0.0   \n",
       "\n",
       "    Day_Ahead_Forecast  \n",
       "0                  4.6  \n",
       "1                 14.1  \n",
       "2                  2.6  \n",
       "3                 31.7  \n",
       "4                 25.2  \n",
       "5                 18.3  \n",
       "6                  2.6  \n",
       "7                 16.2  \n",
       "8                 21.3  \n",
       "9                 24.5  \n",
       "10                16.4  \n",
       "11                 0.0  \n",
       "12                 0.0  \n",
       "13                 0.0  \n",
       "14                 0.0  \n",
       "15                 0.0  \n",
       "16                 0.0  \n",
       "17                 0.0  \n",
       "18                 0.0  \n",
       "19                 0.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_four_dat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location Site Name               object\n",
      "Date                     datetime64[ns]\n",
      "Power_4_Hour_Forecast           float64\n",
      "Day_Ahead_Forecast              float64\n",
      "dtype: object\n",
      "(87620, 4)\n"
     ]
    }
   ],
   "source": [
    "print(one_four_dat.dtypes)\n",
    "print(one_four_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_dat = solar_dat[[\"Date\", \"Location Site Name\", \"PV\", \"Power(MW)\", \"Capacity\"]]\n",
    "solar_dat = solar_dat.rename(columns = {\"Power(MW)\" : \"Actual_Power\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_location_merge = one_four_dat.merge(solar_dat, how = 'inner', on = ['Date', 'Location Site Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Location Site Name                Date  Power_4_Hour_Forecast   \n",
      "0       Bethel Array 2020-05-04 08:00:00                   29.0  \\\n",
      "1       Bethel Array 2020-05-04 09:00:00                   36.1   \n",
      "2       Bethel Array 2020-05-04 10:00:00                   31.3   \n",
      "3       Bethel Array 2020-05-04 11:00:00                   35.8   \n",
      "4       Bethel Array 2020-05-04 12:00:00                   35.3   \n",
      "5       Bethel Array 2020-05-04 13:00:00                   32.5   \n",
      "6       Bethel Array 2020-05-04 14:00:00                   18.1   \n",
      "7       Bethel Array 2020-05-04 15:00:00                   10.6   \n",
      "8       Bethel Array 2020-05-04 16:00:00                    9.4   \n",
      "9       Bethel Array 2020-05-04 17:00:00                    6.3   \n",
      "\n",
      "   Day_Ahead_Forecast                PV  Actual_Power Capacity  \n",
      "0                 4.6  Utility Scale PV         259.4     52MW  \n",
      "1                14.1  Utility Scale PV         342.8     52MW  \n",
      "2                 2.6  Utility Scale PV         428.7     52MW  \n",
      "3                31.7  Utility Scale PV         398.3     52MW  \n",
      "4                25.2  Utility Scale PV         228.0     52MW  \n",
      "5                18.3  Utility Scale PV         286.7     52MW  \n",
      "6                 2.6  Utility Scale PV         170.5     52MW  \n",
      "7                16.2  Utility Scale PV         149.8     52MW  \n",
      "8                21.3  Utility Scale PV         130.9     52MW  \n",
      "9                24.5  Utility Scale PV          86.1     52MW  \n",
      "(87660, 7)\n",
      "['Location Site Name', 'Date', 'Power_4_Hour_Forecast', 'Day_Ahead_Forecast', 'PV', 'Actual_Power', 'Capacity']\n"
     ]
    }
   ],
   "source": [
    "print(date_location_merge.head(10))\n",
    "print(date_location_merge.shape)\n",
    "print(list(date_location_merge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date_location_merge.to_csv('Actual_vs_Forecasted.csv', header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87620, 4)\n",
      "Location Site Name               object\n",
      "Date                     datetime64[ns]\n",
      "Power_4_Hour_Forecast           float64\n",
      "Day_Ahead_Forecast              float64\n",
      "dtype: object\n",
      "['Date', 'Location Site Name', 'PV', 'Actual_Power', 'Capacity']\n",
      "['Bethel Array' \"Aaron's Creek Array\" 'Preston Road Array'\n",
      " 'East Fork Array' 'Owensville Array' 'Anstelt Array' 'Millvale Array'\n",
      " 'Oak Hills Array' 'Lincoln Heights Array' 'Norwood Array']\n"
     ]
    }
   ],
   "source": [
    "print(one_four_dat.shape)\n",
    "print(one_four_dat.dtypes)\n",
    "print(list(solar_dat))\n",
    "print(one_four_dat['Location Site Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                  datetime64[ns]\n",
      "Location Site Name            object\n",
      "PV                            object\n",
      "Actual_Power                 float64\n",
      "Capacity                      object\n",
      "dtype: object\n",
      "['Date', 'Location Site Name', 'PV', 'Actual_Power', 'Capacity']\n"
     ]
    }
   ],
   "source": [
    "print(solar_dat.dtypes)\n",
    "print(list(solar_dat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Looking for discrepancies in my merged data.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__It looks like some rows are being dupliciated for each location after each merge__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                  8760\n",
      "Location Site Name    8760\n",
      "PV                    8760\n",
      "Actual_Power          8760\n",
      "Capacity              8760\n",
      "dtype: int64\n",
      "Location Site Name       8762\n",
      "Date                     8762\n",
      "Power_4_Hour_Forecast    8762\n",
      "Day_Ahead_Forecast       8762\n",
      "dtype: int64\n",
      "Location Site Name       8760\n",
      "Date                     8760\n",
      "Power_4_Hour_Forecast    8760\n",
      "dtype: int64\n",
      "Location Site Name    8760\n",
      "Date                  8760\n",
      "Day_Ahead_Forecast    8760\n",
      "dtype: int64\n",
      "Location Site Name       8766\n",
      "Date                     8766\n",
      "Power_4_Hour_Forecast    8766\n",
      "Day_Ahead_Forecast       8766\n",
      "PV                       8766\n",
      "Actual_Power             8766\n",
      "Capacity                 8766\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(solar_dat[solar_dat['Location Site Name'] == \"Aaron's Creek Array\"].count())\n",
    "print(one_four_dat[one_four_dat['Location Site Name'] == \"Aaron's Creek Array\"].count())\n",
    "print(four_hr_dat[four_hr_dat['Location Site Name'] == \"Aaron's Creek Array\"].count())\n",
    "print(one_day_dat[one_day_dat['Location Site Name'] == \"Aaron's Creek Array\"].count())\n",
    "print(date_location_merge[date_location_merge['Location Site Name'] == \"Aaron's Creek Array\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                  8760\n",
      "Location Site Name    8760\n",
      "PV                    8760\n",
      "Actual_Power          8760\n",
      "Capacity              8760\n",
      "dtype: int64\n",
      "Location Site Name       8762\n",
      "Date                     8762\n",
      "Power_4_Hour_Forecast    8762\n",
      "Day_Ahead_Forecast       8762\n",
      "dtype: int64\n",
      "Location Site Name       8766\n",
      "Date                     8766\n",
      "Power_4_Hour_Forecast    8766\n",
      "Day_Ahead_Forecast       8766\n",
      "PV                       8766\n",
      "Actual_Power             8766\n",
      "Capacity                 8766\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(solar_dat[solar_dat['Location Site Name'] == 'Bethel Array'].count())\n",
    "print(one_four_dat[one_four_dat['Location Site Name'] == 'Bethel Array'].count())\n",
    "print(date_location_merge[date_location_merge['Location Site Name'] == 'Bethel Array'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                  8760\n",
      "Location Site Name    8760\n",
      "PV                    8760\n",
      "Actual_Power          8760\n",
      "Capacity              8760\n",
      "dtype: int64\n",
      "Location Site Name       8762\n",
      "Date                     8762\n",
      "Power_4_Hour_Forecast    8762\n",
      "Day_Ahead_Forecast       8762\n",
      "dtype: int64\n",
      "Location Site Name       8766\n",
      "Date                     8766\n",
      "Power_4_Hour_Forecast    8766\n",
      "Day_Ahead_Forecast       8766\n",
      "PV                       8766\n",
      "Actual_Power             8766\n",
      "Capacity                 8766\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(solar_dat[solar_dat['Location Site Name'] == 'East Fork Array'].count())\n",
    "print(one_four_dat[one_four_dat['Location Site Name'] == 'East Fork Array'].count())\n",
    "print(date_location_merge[date_location_merge['Location Site Name'] == 'East Fork Array'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1     744\n",
       "2     672\n",
       "3     746\n",
       "4     720\n",
       "5     744\n",
       "6     720\n",
       "7     744\n",
       "8     744\n",
       "9     720\n",
       "10    744\n",
       "11    720\n",
       "12    744\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_date = one_four_dat[one_four_dat['Location Site Name'] == 'East Fork Array'].Date.sort_values()\n",
    "forecast_date_month = pd.DatetimeIndex(forecast_date).month\n",
    "forecast_date_month.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1     744\n",
       "2     672\n",
       "3     750\n",
       "4     720\n",
       "5     744\n",
       "6     720\n",
       "7     744\n",
       "8     744\n",
       "9     720\n",
       "10    744\n",
       "11    720\n",
       "12    744\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_location_merge_date = date_location_merge[date_location_merge['Location Site Name'] == 'East Fork Array'].Date.sort_values()\n",
    "date_location_merge_date = pd.DatetimeIndex(date_location_merge_date).month\n",
    "date_location_merge_date.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_date = solar_dat[solar_dat['Location Site Name'] == 'Bethel Array'].Date.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_date = one_four_dat[one_four_dat['Location Site Name'] == 'Bethel Array'].Date.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_location_merge_date = date_location_merge[date_location_merge['Location Site Name'] == 'Bethel Array'].Date.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_date = pd.to_datetime(solar_date)\n",
    "forecast_date = pd.to_datetime(forecast_date)\n",
    "date_location_merge_date = pd.to_datetime(date_location_merge_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Count how many time a month appears for the Bethel Array location__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1     744\n",
       "2     672\n",
       "3     744\n",
       "4     720\n",
       "5     744\n",
       "6     720\n",
       "7     744\n",
       "8     744\n",
       "9     720\n",
       "10    744\n",
       "11    720\n",
       "12    744\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solar_date_month = pd.DatetimeIndex(solar_date).month\n",
    "solar_date_month.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1     744\n",
       "2     672\n",
       "3     746\n",
       "4     720\n",
       "5     744\n",
       "6     720\n",
       "7     744\n",
       "8     744\n",
       "9     720\n",
       "10    744\n",
       "11    720\n",
       "12    744\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_date_month = pd.DatetimeIndex(forecast_date).month\n",
    "forecast_date_month.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1     744\n",
       "2     672\n",
       "3     750\n",
       "4     720\n",
       "5     744\n",
       "6     720\n",
       "7     744\n",
       "8     744\n",
       "9     720\n",
       "10    744\n",
       "11    720\n",
       "12    744\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_location_merge_month = pd.DatetimeIndex(date_location_merge_date).month\n",
    "date_location_merge_month.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now count how many days and compare between the standard and joined datasets. <br> Above code tells which month has too many days and below shows which exact day has duplicates.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "1     24\n",
      "2     24\n",
      "3     24\n",
      "4     24\n",
      "5     24\n",
      "6     24\n",
      "7     24\n",
      "8     24\n",
      "9     24\n",
      "10    24\n",
      "11    24\n",
      "12    24\n",
      "13    24\n",
      "14    24\n",
      "15    24\n",
      "16    24\n",
      "17    24\n",
      "18    24\n",
      "19    24\n",
      "20    24\n",
      "21    24\n",
      "22    24\n",
      "23    24\n",
      "24    24\n",
      "25    24\n",
      "26    24\n",
      "27    24\n",
      "28    24\n",
      "29    24\n",
      "30    24\n",
      "31    24\n",
      "Name: count, dtype: int64\n",
      "Date\n",
      "1     24\n",
      "2     24\n",
      "3     24\n",
      "4     24\n",
      "5     24\n",
      "6     24\n",
      "7     24\n",
      "8     26\n",
      "9     24\n",
      "10    24\n",
      "11    24\n",
      "12    24\n",
      "13    24\n",
      "14    24\n",
      "15    24\n",
      "16    24\n",
      "17    24\n",
      "18    24\n",
      "19    24\n",
      "20    24\n",
      "21    24\n",
      "22    24\n",
      "23    24\n",
      "24    24\n",
      "25    24\n",
      "26    24\n",
      "27    24\n",
      "28    24\n",
      "29    24\n",
      "30    24\n",
      "31    24\n",
      "Name: count, dtype: int64\n",
      "Date\n",
      "1     24\n",
      "2     24\n",
      "3     24\n",
      "4     24\n",
      "5     24\n",
      "6     24\n",
      "7     24\n",
      "8     30\n",
      "9     24\n",
      "10    24\n",
      "11    24\n",
      "12    24\n",
      "13    24\n",
      "14    24\n",
      "15    24\n",
      "16    24\n",
      "17    24\n",
      "18    24\n",
      "19    24\n",
      "20    24\n",
      "21    24\n",
      "22    24\n",
      "23    24\n",
      "24    24\n",
      "25    24\n",
      "26    24\n",
      "27    24\n",
      "28    24\n",
      "29    24\n",
      "30    24\n",
      "31    24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DatetimeIndex(solar_date[solar_date.dt.month == 3]).day.value_counts().sort_index())\n",
    "print(pd.DatetimeIndex(forecast_date[forecast_date.dt.month == 3]).day.value_counts().sort_index())\n",
    "print(pd.DatetimeIndex(date_location_merge_date[date_location_merge_date.dt.month == 3]).day.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Find indexes of duplicated day and hour__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2360,\n",
       " 2361,\n",
       " 15022,\n",
       " 15023,\n",
       " 18260,\n",
       " 18261,\n",
       " 34983,\n",
       " 34984,\n",
       " 40783,\n",
       " 40784,\n",
       " 48223,\n",
       " 48224,\n",
       " 54023,\n",
       " 54024,\n",
       " 62783,\n",
       " 62784,\n",
       " 71543,\n",
       " 71544,\n",
       " 74626,\n",
       " 74627]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_hr_dat.index[four_hr_dat['Date'] == '2020-03-08 03:00:00'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1586,\n",
       " 1587,\n",
       " 10346,\n",
       " 10347,\n",
       " 19548,\n",
       " 19549,\n",
       " 30669,\n",
       " 30670,\n",
       " 39429,\n",
       " 39430,\n",
       " 45306,\n",
       " 45307,\n",
       " 58294,\n",
       " 58295,\n",
       " 63716,\n",
       " 63717,\n",
       " 72476,\n",
       " 72477,\n",
       " 83266,\n",
       " 83267]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_day_dat.index[one_day_dat['Date'] == '2020-03-08 03:00:00'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This code below will delete certain rows based off the index__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#four_hr_dat.drop([1587,10347,...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__From my investigation, the month of March has a duplicate date specifically 03/08/2020 03:00 for all the locations. When I join my data it will create more duplicates.<br> <br> I do not know if the duplicates are the result of a clerical error or the reading for that date was done twice.__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
